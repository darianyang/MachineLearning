{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Progress Coordinate and Conformational Selection for Molecular Dynamics\n",
    "### ML Final Project : Darian Yang\n",
    "\n",
    "#### Original Proposal: \n",
    "My project idea is to take an ensemble of MD trajectories where multiple candidate progress coordinates are calculated per frame, and to then use machine learning to rank each candidate coordinate and select the best progress descriptor. Another thought is to potentially standardize the coordinates, then take a linear combination of each coordinate and optimize the weight of each. I'm not sure what ML technique will be best here, but perhaps using decision trees for ranking purposes or optimizing a target function that can approximate the quality of a single or multi-dimensional coordinate. In the test/training datasets, I will use trajectories that make it to a pre-defined target state as the labeled successful input. For the actual simulation data to be used, I am not sure which dataset to choose yet but I have a few from my research projects available to choose from (all of which are proteins or protein-ligand complexes). Ideally I will try it out for multiple systems.\n",
    "\n",
    "#### Current Implementation:\n",
    "I will start with a 1Âµs standard MD simulation of 2 different states. I will calculate multiple features for each simulation and then feed all of this data into a classification model. Using cpptraj, I calculated 59 features for a 1000 frame subset of both 2kod and 1a43 trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load the feature sets from each simulation dataset\n",
    "d1 = np.loadtxt(\"data/2kod_features.dat\")\n",
    "d2 = np.loadtxt(\"data/1a43_features.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build feature dataset with both simulations\n",
    "features = np.vstack((d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 60)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#Frame', 'RMS_M1_NMR', 'RMS_H9M1_NMR', 'RMS_M2_NMR',\n",
       "       'RMS_H9M2_NMR', 'RMS_Heavy_NMR', 'RMS_Backbone_NMR',\n",
       "       'RMS_Dimer_Int_NMR', 'RMS_Key_Int_NMR', 'RMS_M1_XTAL',\n",
       "       'RMS_H9M1_XTAL', 'RMS_M2_XTAL', 'RMS_H9M2_XTAL', 'RMS_Heavy_XTAL',\n",
       "       'RMS_Backbone_XTAL', 'RMS_Dimer_Int_XTAL', 'RMS_Key_Int_XTAL',\n",
       "       'RMS_M1_HEX', 'RMS_H9M1_HEX', 'RMS_M2_HEX', 'RMS_H9M2_HEX',\n",
       "       'RMS_Heavy_HEX', 'RMS_Backbone_HEX', 'RMS_Dimer_Int_HEX',\n",
       "       'RMS_Key_Int_HEX', 'RMS_M1_PENT', 'RMS_H9M1_PENT', 'RMS_M2_PENT',\n",
       "       'RMS_H9M2_PENT', 'RMS_Heavy_PENT', 'RMS_Backbone_PENT',\n",
       "       'RMS_Dimer_Int_PENT', 'RMS_Key_Int_PENT', 'c2_angle',\n",
       "       'helix_angle_3pt', 'o_angle_m1', 'o_angle_m2', 'RoG', 'RoG-cut',\n",
       "       'Total_SASA', 'Num_Inter_Contacts[native]',\n",
       "       'Num_Inter_Contacts[nonnative]', 'Num_Intra_Contacts[native]',\n",
       "       'Num_Intra_Contacts[nonnative]', 'M1-E175-Oe_M2-W184-He1',\n",
       "       'M2-E175-Oe_M1-W184-He1', 'M1-E175-Oe_M1-T148-HG1',\n",
       "       'M2-E175-Oe_M2-T148-HG1', 'M1-M2-COM', 'M1-M2-L46', 'phi:32',\n",
       "       'psi:32', 'chi1:32', 'chi2:32', 'chi3:32', 'phi:120', 'psi:120',\n",
       "       'chi1:120', 'chi2:120', 'chi3:120'], dtype='<U29')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = np.loadtxt(\"data/2kod_features.dat\", comments=None, max_rows=1, dtype=str)\n",
    "feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the binary classification dataset\n",
    "# 0 for every frame from d1 and 1 for every frame from d2\n",
    "classifiers = np.hstack((np.zeros(d1.shape[0]), np.ones(d2.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first scale the feature data\n",
    "scaler = StandardScaler()\n",
    "# note to skip the first column since this is the frame number\n",
    "feats_scaled = scaler.fit_transform(features[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training/test\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(feats_scaled, classifiers, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 59)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I scaled the data and split it, now I will build some basic models to try to classify which conformation the frame belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring\n",
    "To score my models, I will use the ROC AUC. The following reccommendations are from [here](https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc):\n",
    "\n",
    "* You should use it when you ultimately care about ranking predictions and not necessarily about outputting well-calibrated probabilities.\n",
    "* You should not use it when your data is heavily imbalanced. The intuition is the following: false positive rate for highly imbalanced datasets is pulled down due to a large number of true negatives.\n",
    "* You should use it when you care equally about positive and negative classes. It naturally extends the imbalanced data discussion from the last section. If we care about true negatives as much as we care about true positives then it totally makes sense to use ROC AUC.\n",
    "\n",
    "In my case, I have an equal balance of positive (1) and negative (0) cases, and I care equally about both (one protein conformation or the other). Just in case, I will implement include other scoring methods as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def calc_score(model, score=\"auc\", X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    \"\"\"\n",
    "    Find a scoring metric using an sklearn model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    score : str\n",
    "        'auc', 'f1', 'acc'\n",
    "    \"\"\"\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if score == \"auc\":\n",
    "        metric = metrics.roc_auc_score(y_test, y_pred)\n",
    "        #print(np.testing.assert_array_equal(y_test, y_pred))\n",
    "    elif score == \"f1\":\n",
    "        metric = metrics.f1_score(y_test, y_pred)\n",
    "    elif score == \"acc\":\n",
    "        metric = metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    # RF only\n",
    "    if hasattr(model, \"oob_score_\"):\n",
    "        print(f\"OOB: {model.oob_score_}\")\n",
    "        print(f\"{score}: {metric}\")\n",
    "        #return metric\n",
    "        #return model.oob_score_, auc\n",
    "        return model\n",
    "    else:\n",
    "        print(f\"{score}: {metric}\")\n",
    "        #return metric\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(linear_model.LogisticRegression(), \"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calc_score() missing 4 required positional arguments: 'X_train', 'y_train', 'X_test', and 'y_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-8fb8f1bb6e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# top feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeat_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: calc_score() missing 4 required positional arguments: 'X_train', 'y_train', 'X_test', and 'y_test'"
     ]
    }
   ],
   "source": [
    "rf = calc_score(ensemble.RandomForestClassifier())\n",
    "plt.plot(rf.feature_importances_)\n",
    "# top feature\n",
    "feat_names[np.where(rf.feature_importances_ == np.max(rf.feature_importances_))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RMS_Backbone_PENT', 'o_angle_m1', 'RMS_Dimer_Int_XTAL',\n",
       "       'RMS_Backbone_XTAL', 'RMS_H9M2_XTAL', 'RMS_H9M2_PENT',\n",
       "       'RMS_Dimer_Int_PENT', 'RMS_M1_PENT', 'c2_angle',\n",
       "       'RMS_Dimer_Int_NMR'], dtype='<U29')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = np.argpartition(rf.feature_importances_, -10)[-10:]\n",
    "feat_names[top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next maybe run this 100 times and collect a weighted histogram of the resulting rankings? \n",
    "\n",
    "Also later, maybe take the C$\\alpha$ inter monomer distance matrix and look for best coordinate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
