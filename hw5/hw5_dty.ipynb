{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW5 Band Gap Prediction\n",
    "### Darian Yang\n",
    "\n",
    "You can start with basic models, and then try your best to optimize your predictions by using more sophisticated models, feature engineering, and fine-tuning the hyperparameters. The grade of this homework will be based on the score you get on Kaggle. \n",
    "\n",
    "There is no specific requirement for a written summary for this homework, but please leave some necessary notes/comments in your submission to help the grader understand your workflow.\n",
    "\n",
    "#### TODO:\n",
    "* Given the training data: X_train and Y_train\n",
    "* Find best suitable features\n",
    "* You are allowed to build any type of regression model\n",
    "* You are allowed to use any type of data processing\n",
    "* Find the best performing model\n",
    "* Use your model to score Y_test\n",
    "\n",
    "This dataset provides quantitative measurements of the band gap (Egap) for a set of inorganic crystaline materials.\n",
    "\n",
    "#### File descriptions\n",
    "* X_train_kaggle.csv - the training set: file with Material column\n",
    "* y_train_kaggle.csv - the training set: Egap for training with Id column\n",
    "* X_test_kaggle.csv - the test set: file with Material column with Id column that you should predict\n",
    "* y_sample_submission.csv - a sample submission file in the correct format\n",
    "\n",
    "#### Data fields\n",
    "* Id - an id unique to a given material ( Please note 'Id' is the last column)\n",
    "* D1-D132 - chemical descriptor to a given material\n",
    "* Egap - Egap values in y- files\n",
    "\n",
    "The evaluation metric for this competition is Mean absolute error .\n",
    "\n",
    "#### Submission Format\n",
    "For every molecule in the dataset, submission files should contain two columns: Id and Egap.\n",
    "\n",
    "The file should contain a header and have the following format:\n",
    "```\n",
    "Id,Egap\n",
    "1,0.456\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train_kaggle.csv\", index_col=133).to_numpy()\n",
    "y_train = pd.read_csv(\"y_train_kaggle.csv\", index_col=1).to_numpy()\n",
    "X_test = pd.read_csv(\"X_test_kaggle.csv\", index_col=133).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ID = pd.read_csv(\"X_test_kaggle.csv\",index_col=133).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4132,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4132,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(TEST_ID).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ID = pd.read_csv(\"X_train_kaggle.csv\",index_col=0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9640, 133)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the material column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9640, 132)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[:,1:]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4132, 132)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test[:,1:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9640, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9640,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape to 1d\n",
    "y_train = y_train[:,0]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(model, save_to=None, X_train=X_train, y_train=y_train, X_test=X_test):\n",
    "    \n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_test = model.predict(X_test)\n",
    "\n",
    "    if save_to:\n",
    "        ret = {\"Id\":TEST_ID, \"Egap\":y_test}\n",
    "        ret = pd.DataFrame(data=ret)\n",
    "        ret.set_index(\"Id\")\n",
    "        ret.to_csv(save_to, index=False)\n",
    "    \n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calc_score(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Find the mse using an sklearn model.\n",
    "    \"\"\"\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # RF\n",
    "    if hasattr(model, \"oob_score_\"):\n",
    "        #print(f\"OOB: {model.oob_score_}\")\n",
    "        return model.oob_score_, mse\n",
    "    else:\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training/test\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = \\\n",
    "    model_selection.train_test_split(X_train_scaled, y_train, test_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1887630612528222"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(linear_model.LinearRegression(), X_train_b, y_train_b, X_test_b, y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6915955076438205, 0.7721188464802152)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(RandomForestRegressor(max_depth=None, oob_score=True), X_train_b, y_train_b, X_test_b, y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6899596121795617, 0.768416162047233)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(RandomForestRegressor(max_depth=None, oob_score=True, criterion=\"absolute_error\"), X_train_b, y_train_b, X_test_b, y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6913443127058705, 0.7730645766108283)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(RandomForestRegressor(max_depth=None, oob_score=True, criterion=\"poisson\"), X_train_b, y_train_b, X_test_b, y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/lchong/dty7/Apps/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2211295173422594"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.LinearSVR(), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I will submit kaggle using random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.133309  , 2.57074427, 2.68455313, ..., 1.64507733, 1.623616  ,\n",
       "       3.172862  ])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker(RandomForestRegressor(max_depth=None), \"rf.csv\", X_train=X_train_scaled, y_train=y_train, X_test=X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So between linear regression, a linear SVM, and random forest, RF is the best but note that we can't extrapolate with RF so it might not be the best option here. I will try optimizing SVMs since this dataset is smaller than the last HW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/lchong/dty7/Apps/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.216609871226856"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.LinearSVR(max_iter=10000, C=1), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/lchong/dty7/Apps/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2170656185325868"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.LinearSVR(max_iter=10000, C=10), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/lchong/dty7/Apps/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7660575937714196"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.LinearSVR(max_iter=10000, C=100), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2166339185799946"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.SVR(kernel=\"linear\", C=1, cache_size=1000), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9560429991532254"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.SVR(kernel=\"rbf\", C=1, cache_size=1000), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that from literature for a similar problem (https://pubs.acs.org/doi/full/10.1021/acs.jpclett.8b00124):\n",
    "\n",
    "C and γ were optimized to 10 and 0.01 for SVR, respectively, while ϵ was set at 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657977947153491"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.SVR(kernel=\"rbf\", C=10, cache_size=1000), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647272137025013"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.SVR(kernel=\"rbf\", C=10, gamma=0.01, cache_size=1000), X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647272137025013"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(svm.SVR(kernel=\"rbf\", C=10, gamma=0.01, epsilon=0.1, cache_size=1000), \n",
    "           X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's actually optimize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_2d_range = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_2d_range = [0.01, 0.1, 1, 10, 100]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = svm.SVR(C=C, gamma=gamma, cache_size=1000)\n",
    "        clf.fit(X_train_b, y_train_b)\n",
    "        y_pred = clf.predict(X_test_b)\n",
    "        mse = mean_squared_error(y_test_b, y_pred)\n",
    "        classifiers.append((C, gamma, clf, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.01, SVR(C=0.01, cache_size=1000, gamma=0.01), 1.8236485113967649),\n",
       " (0.01, 0.1, SVR(C=0.01, cache_size=1000, gamma=0.1), 2.5585353692385726),\n",
       " (0.01, 1, SVR(C=0.01, cache_size=1000, gamma=1), 2.602948806597704),\n",
       " (0.01, 10, SVR(C=0.01, cache_size=1000, gamma=10), 2.6043677219436296),\n",
       " (0.01, 100, SVR(C=0.01, cache_size=1000, gamma=100), 2.604429664100975),\n",
       " (0.1, 0.01, SVR(C=0.1, cache_size=1000, gamma=0.01), 1.2154735920005613),\n",
       " (0.1, 0.1, SVR(C=0.1, cache_size=1000, gamma=0.1), 2.196404116055674),\n",
       " (0.1, 1, SVR(C=0.1, cache_size=1000, gamma=1), 2.532059427595707),\n",
       " (0.1, 10, SVR(C=0.1, cache_size=1000, gamma=10), 2.5471858403151155),\n",
       " (0.1, 100, SVR(C=0.1, cache_size=1000, gamma=100), 2.5477969447261923),\n",
       " (1, 0.01, SVR(C=1, cache_size=1000, gamma=0.01), 0.9437444438182191),\n",
       " (1, 0.1, SVR(C=1, cache_size=1000, gamma=0.1), 1.3781565019410396),\n",
       " (1, 1, SVR(C=1, cache_size=1000, gamma=1), 2.2712499225498193),\n",
       " (1, 10, SVR(C=1, cache_size=1000, gamma=10), 2.363289627231711),\n",
       " (1, 100, SVR(C=1, cache_size=1000, gamma=100), 2.368205412804101),\n",
       " (10, 0.01, SVR(C=10, cache_size=1000, gamma=0.01), 0.8647272137025013),\n",
       " (10, 0.1, SVR(C=10, cache_size=1000, gamma=0.1), 1.2643462320230447),\n",
       " (10, 1, SVR(C=10, cache_size=1000, gamma=1), 2.120415969623712),\n",
       " (10, 10, SVR(C=10, cache_size=1000, gamma=10), 2.253702191546682),\n",
       " (10, 100, SVR(C=10, cache_size=1000, gamma=100), 2.2631667925075023),\n",
       " (100, 0.01, SVR(C=100, cache_size=1000, gamma=0.01), 0.955194386515464),\n",
       " (100, 0.1, SVR(C=100, cache_size=1000, gamma=0.1), 1.2887438628938668),\n",
       " (100, 1, SVR(C=100, cache_size=1000, gamma=1), 2.1204159959251085),\n",
       " (100, 10, SVR(C=100, cache_size=1000, gamma=10), 2.2537011504688884),\n",
       " (100, 100, SVR(C=100, cache_size=1000, gamma=100), 2.2631670102877557)]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, the optimized rbf kernel svr is the same as from the paper, and overall probably not as good as RF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will submit to make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.69489438, 2.24564259, 3.23115338, ..., 1.64694377, 1.82499312,\n",
       "       3.13586865])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker(svm.SVR(kernel=\"rbf\", C=10, gamma=0.01, cache_size=1000), \"svm.csv\", X_train=X_train_scaled, y_train=y_train, X_test=X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suspected, not as good as rf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so let's optimize RF hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=80, cv=3, verbose=1, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 110.5min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed: 127.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=80, n_jobs=8,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "rf_random.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353321062429926"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(RandomForestRegressor(**rf_random.best_params_), \n",
    "           X_train=X_train_b, y_train=y_train_b, X_test=X_test_b, y_test=y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does score better in mse compared to the default, let's submit it to kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.14690964, 2.97176267, 2.64893846, ..., 1.80630918, 1.70350869,\n",
       "       3.08582956])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker(RandomForestRegressor(**rf_random.best_params_), \"rf.csv\", X_train=X_train_scaled, y_train=y_train, X_test=X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also scored well on kaggle, just barely above the optimized solution. So still a little more to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll try to narrow the RF paramater search using a more comprehensive gridsearchCV around the parameters identified from randomsearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [30, 40, 50],\n",
    "    'max_features': [11, 12],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [600, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/home/dty7/Apps/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  4.1min\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
