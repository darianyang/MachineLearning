{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRfi_A6L-ZN_"
   },
   "source": [
    "# Graph Convolutional Neural Netowrk (GCNN) Homework\n",
    "\n",
    "* There are two datasets in the `data` folder: `train.pt`, `test.pt`. You will train a GCNN on the training dataset, then predict on the test dataset.\n",
    "* There are two parts in the documentation. `Part I` gives a custom `Dataset` object and loads the datasets. The `QM_Dataset` object inheriates from torch geometric `Dataset` object. `Part II` is an example solution.\n",
    "* This HW is implemented with [Pytorch Geometric (PyG)](https://pytorch-geometric.readthedocs.io/en/latest/index.html). Another popular libraray for implementing graph neural networks is [Deep Graph Library (DGL)](https://www.dgl.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6z5zXzc2-ZOD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JrdqqRyp-ZOE"
   },
   "source": [
    "## Part I. The training and testing dataset are provided\n",
    "\n",
    "- The training and testing datasets were pre-processed graphs. The training dataset contains 20,000 graphs, while the test dataset contains 2,000 graphs.\n",
    "- Each graph contais the following components \n",
    "\n",
    "    - `x`, the matrix containing node features, `[num_of_nodes, num_node_features=11]`\n",
    "    - `edge_index`, the matrix containing connection information about different nodes, `[2, num_of_edges]`\n",
    "    - `y`, the label for the graph, `scaler`. The value is set to `0` in the test dataset\n",
    "    - `pos`, the matrix containing the node positions, `[num_of_nodes, 3]`\n",
    "    - `edge_attr`, the matrix containing the edge information, `[num_edges, 4]`\n",
    "    - `names`, index for the graph. For example, `gdb_59377`\n",
    "\n",
    "- Depending on the graph convolutional layer that is used, different components are needed. For the most basic application, `x`, `edge_index` and `y` will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXVJcJjo-ZOF"
   },
   "outputs": [],
   "source": [
    "class QM_Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__(self)\n",
    "        self.path = path\n",
    "        self.data = torch.load(self.path)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return self.data[idx]\n",
    "        \n",
    "train_path = \"data2/train.pt\"\n",
    "test_path = \"data2/test.pt\"\n",
    "\n",
    "train_data_ = QM_Dataset(train_path)\n",
    "#The training dataset can be splitted into two parts for validation purpose\n",
    "train_data, validate_data = torch.utils.data.random_split(train_data_, [19000, 1000])\n",
    "test_data = QM_Dataset(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMYYRRR0-ZOG"
   },
   "source": [
    "## Part II. Example solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPg-AIWd-ZOG"
   },
   "outputs": [],
   "source": [
    "# Define the network\n",
    "# Many convolutional layers are availabel in torch_geometric.nn\n",
    "# Here NNConv is used as an example\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_features=11, dim=64):\n",
    "        super().__init__()\n",
    "        self.lin0 = torch.nn.Linear(num_features, dim)\n",
    "        nn = Sequential(Linear(4, 128), ReLU(), Linear(128, dim * dim))\n",
    "        self.conv = NNConv(dim, dim, nn, aggr='mean')  #You will need to replace with your own convolutiona layers here\n",
    "        self.set2set = Set2Set(dim, processing_steps=3)  #The set2set is used to map from nodes to graphs\n",
    "        self.lin1 = torch.nn.Linear(2 * dim, dim)\n",
    "        self.lin2 = torch.nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.lin0(data.x))  #data.x size [batch_num_nodes, num_node_features]\n",
    "        for _ in range(3):\n",
    "            out = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
    "        out = self.set2set(out, data.batch)  #[batch_num_nodes, dim] ==> [batch_num_graphs, dim*2]\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eumyKXt1-ZOH"
   },
   "outputs": [],
   "source": [
    "# Define a trianing and evaluating function\n",
    "def train(loader):\n",
    "    \"\"\"Takes in training dataset loader,\n",
    "    train the model one step,\n",
    "    update the parameters,\n",
    "    return the current loss\"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.mse_loss(model(data), data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(loader.dataset)\n",
    "\n",
    "def eval(loader):\n",
    "    \"\"\"Takes the validation dataset loader,\n",
    "    return the validation MAE\"\"\"\n",
    "    model.eval()\n",
    "    Ys = []\n",
    "    Names = []\n",
    "    Y_true = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        ys = out.to(\"cpu\").tolist()\n",
    "        Ys += ys\n",
    "        Names += data['name']\n",
    "        Y_true += data['y']\n",
    "    assert(len(Y_true) == len(Ys))\n",
    "    E = 0\n",
    "    for i in range(len(Y_true)):\n",
    "        E += abs(Y_true[i] - Ys[i])\n",
    "    return E/len(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29AeJ7Q6-ZOI"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_loader = DataLoader(train_data, batch_size=128)\n",
    "validate_loader = DataLoader(validate_data, batch_size=128)\n",
    "test_loader = DataLoader(test_data, batch_size=8)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyAA9GLE-ZOJ",
    "outputId": "4b9c1488-7f94-46f2-8299-ce13ac50ff10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, MAE: 2.8424060\n",
      "Epoch: 001, Loss: 2.6428377, MAE: 0.9120902\n",
      "Epoch: 002, Loss: 1.4618543, MAE: 0.8981929\n",
      "Epoch: 003, Loss: 1.4353232, MAE: 0.8911480\n",
      "Epoch: 004, Loss: 1.4149225, MAE: 0.8850090\n",
      "Epoch: 005, Loss: 1.3891462, MAE: 0.8611026\n",
      "Epoch: 006, Loss: 1.3565412, MAE: 0.8406896\n",
      "Epoch: 007, Loss: 1.3250736, MAE: 0.8318036\n",
      "Epoch: 008, Loss: 1.3061361, MAE: 0.8283791\n",
      "Epoch: 009, Loss: 1.2951733, MAE: 0.8256869\n",
      "Epoch: 010, Loss: 1.2844763, MAE: 0.8202440\n",
      "Epoch: 011, Loss: 1.2746580, MAE: 0.8201486\n",
      "Epoch: 012, Loss: 1.2636615, MAE: 0.8160493\n",
      "Epoch: 013, Loss: 1.2573440, MAE: 0.8200057\n",
      "Epoch: 014, Loss: 1.2504716, MAE: 0.8164753\n",
      "Epoch: 015, Loss: 1.2417441, MAE: 0.8147994\n",
      "Epoch: 016, Loss: 1.2384232, MAE: 0.8136805\n",
      "Epoch: 017, Loss: 1.2336900, MAE: 0.8054752\n",
      "Epoch: 018, Loss: 1.2316047, MAE: 0.8146860\n",
      "Epoch: 019, Loss: 1.2264985, MAE: 0.8085163\n",
      "Epoch: 020, Loss: 1.2215189, MAE: 0.8081459\n",
      "Epoch: 021, Loss: 1.2175943, MAE: 0.8074743\n",
      "Epoch: 022, Loss: 1.2198225, MAE: 0.8108947\n",
      "Epoch: 023, Loss: 1.2117569, MAE: 0.7959535\n",
      "Epoch: 024, Loss: 1.2068685, MAE: 0.7909773\n",
      "Epoch: 025, Loss: 1.2020265, MAE: 0.7897229\n",
      "Epoch: 026, Loss: 1.1964347, MAE: 0.7912307\n",
      "Epoch: 027, Loss: 1.1966341, MAE: 0.7876436\n",
      "Epoch: 028, Loss: 1.1880509, MAE: 0.8049802\n",
      "Epoch: 029, Loss: 1.1938735, MAE: 0.7893320\n",
      "Epoch: 030, Loss: 1.1816288, MAE: 0.7849218\n",
      "Epoch: 031, Loss: 1.1712169, MAE: 0.7848884\n",
      "Epoch: 032, Loss: 1.1674013, MAE: 0.7818661\n",
      "Epoch: 033, Loss: 1.1801887, MAE: 0.7959004\n",
      "Epoch: 034, Loss: 1.1624275, MAE: 0.7833360\n",
      "Epoch: 035, Loss: 1.1537089, MAE: 0.7876033\n",
      "Epoch: 036, Loss: 1.1536466, MAE: 0.8036558\n",
      "Epoch: 037, Loss: 1.1458129, MAE: 0.7826600\n",
      "Epoch: 038, Loss: 1.1367641, MAE: 0.7827355\n",
      "Epoch: 039, Loss: 1.1319845, MAE: 0.7777748\n",
      "Epoch: 040, Loss: 1.1561359, MAE: 0.7837192\n",
      "Epoch: 041, Loss: 1.1324189, MAE: 0.7797843\n",
      "Epoch: 042, Loss: 1.1203070, MAE: 0.7742094\n",
      "Epoch: 043, Loss: 1.1162704, MAE: 0.7729195\n",
      "Epoch: 044, Loss: 1.1114057, MAE: 0.7670397\n",
      "Epoch: 045, Loss: 1.1027834, MAE: 0.7670823\n",
      "Epoch: 046, Loss: 1.1005150, MAE: 0.7660545\n",
      "Epoch: 047, Loss: 1.0982244, MAE: 0.7692490\n",
      "Epoch: 048, Loss: 1.0910885, MAE: 0.7632233\n",
      "Epoch: 049, Loss: 1.0856438, MAE: 0.7657932\n",
      "Epoch: 050, Loss: 1.0996341, MAE: 0.7659776\n",
      "Epoch: 051, Loss: 1.0779005, MAE: 0.7626803\n",
      "Epoch: 052, Loss: 1.0715019, MAE: 0.7624646\n",
      "Epoch: 053, Loss: 1.0687927, MAE: 0.7567796\n",
      "Epoch: 054, Loss: 1.0639679, MAE: 0.7633752\n",
      "Epoch: 055, Loss: 1.0602170, MAE: 0.7559831\n",
      "Epoch: 056, Loss: 1.0670250, MAE: 0.7575474\n",
      "Epoch: 057, Loss: 1.0515213, MAE: 0.7508758\n",
      "Epoch: 058, Loss: 1.0455306, MAE: 0.7521598\n",
      "Epoch: 059, Loss: 1.0378898, MAE: 0.7517567\n",
      "Epoch: 060, Loss: 1.0362486, MAE: 0.7507651\n",
      "Epoch: 061, Loss: 1.0417169, MAE: 0.7536230\n",
      "Epoch: 062, Loss: 1.0665707, MAE: 0.7664092\n",
      "Epoch: 063, Loss: 1.0494845, MAE: 0.7468466\n",
      "Epoch: 064, Loss: 1.0585539, MAE: 0.7491282\n",
      "Epoch: 065, Loss: 1.0259415, MAE: 0.7466499\n",
      "Epoch: 066, Loss: 1.0140586, MAE: 0.7471917\n",
      "Epoch: 067, Loss: 1.0079190, MAE: 0.7496647\n",
      "Epoch: 068, Loss: 1.0029472, MAE: 0.7453049\n",
      "Epoch: 069, Loss: 1.0019764, MAE: 0.7382984\n",
      "Epoch: 070, Loss: 0.9886361, MAE: 0.7375786\n",
      "Epoch: 071, Loss: 0.9854033, MAE: 0.7399015\n",
      "Epoch: 072, Loss: 1.0673294, MAE: 0.7711477\n",
      "Epoch: 073, Loss: 1.0421834, MAE: 0.7539158\n",
      "Epoch: 074, Loss: 0.9968124, MAE: 0.7343914\n",
      "Epoch: 075, Loss: 0.9800337, MAE: 0.7362391\n",
      "Epoch: 076, Loss: 0.9649070, MAE: 0.7335634\n",
      "Epoch: 077, Loss: 0.9620657, MAE: 0.7314517\n",
      "Epoch: 078, Loss: 0.9584742, MAE: 0.7261676\n",
      "Epoch: 079, Loss: 0.9550657, MAE: 0.7275806\n",
      "Epoch: 080, Loss: 0.9562229, MAE: 0.7361457\n",
      "Epoch: 081, Loss: 0.9460651, MAE: 0.7292220\n",
      "Epoch: 082, Loss: 0.9348713, MAE: 0.7287325\n",
      "Epoch: 083, Loss: 0.9296043, MAE: 0.7259867\n",
      "Epoch: 084, Loss: 1.0140382, MAE: 0.7382534\n",
      "Epoch: 085, Loss: 0.9491080, MAE: 0.7330599\n",
      "Epoch: 086, Loss: 0.9334036, MAE: 0.7302076\n",
      "Epoch: 087, Loss: 0.9307389, MAE: 0.7240644\n",
      "Epoch: 088, Loss: 0.9159811, MAE: 0.7239622\n",
      "Epoch: 089, Loss: 0.9121447, MAE: 0.7226198\n",
      "Epoch: 090, Loss: 0.9642201, MAE: 0.7397306\n",
      "Epoch: 091, Loss: 0.9403764, MAE: 0.7263869\n",
      "Epoch: 092, Loss: 0.9226712, MAE: 0.7401924\n",
      "Epoch: 093, Loss: 0.9291772, MAE: 0.7357726\n",
      "Epoch: 094, Loss: 0.8982044, MAE: 0.7247823\n",
      "Epoch: 095, Loss: 0.8938982, MAE: 0.7207291\n",
      "Epoch: 096, Loss: 0.8853075, MAE: 0.7207146\n",
      "Epoch: 097, Loss: 0.8808085, MAE: 0.7121323\n",
      "Epoch: 098, Loss: 0.8874906, MAE: 0.7119195\n",
      "Epoch: 099, Loss: 0.8711844, MAE: 0.7142003\n",
      "Epoch: 100, Loss: 0.8730638, MAE: 0.7148122\n",
      "Epoch: 101, Loss: 0.8658699, MAE: 0.7183324\n",
      "Epoch: 102, Loss: 0.9168958, MAE: 0.7257277\n",
      "Epoch: 103, Loss: 0.8671929, MAE: 0.7137492\n",
      "Epoch: 104, Loss: 0.8543195, MAE: 0.7151755\n",
      "Epoch: 105, Loss: 0.8495116, MAE: 0.7138104\n",
      "Epoch: 106, Loss: 0.8467587, MAE: 0.7078018\n",
      "Epoch: 107, Loss: 0.8523011, MAE: 0.7087785\n",
      "Epoch: 108, Loss: 0.8374607, MAE: 0.7053727\n",
      "Epoch: 109, Loss: 0.8330519, MAE: 0.7081056\n",
      "Epoch: 110, Loss: 0.8252245, MAE: 0.6997950\n",
      "Epoch: 111, Loss: 0.8294539, MAE: 0.7048385\n",
      "Epoch: 112, Loss: 0.8232822, MAE: 0.7027926\n",
      "Epoch: 113, Loss: 0.8198178, MAE: 0.7021078\n",
      "Epoch: 114, Loss: 0.8338847, MAE: 0.7015729\n",
      "Epoch: 115, Loss: 0.8137011, MAE: 0.6978649\n",
      "Epoch: 116, Loss: 0.8104490, MAE: 0.6985343\n",
      "Epoch: 117, Loss: 0.8402950, MAE: 0.7072796\n",
      "Epoch: 118, Loss: 0.8134038, MAE: 0.6991935\n",
      "Epoch: 119, Loss: 0.8062256, MAE: 0.6930398\n",
      "Epoch: 120, Loss: 0.8090929, MAE: 0.7020106\n",
      "Epoch: 121, Loss: 0.7981126, MAE: 0.6946278\n",
      "Epoch: 122, Loss: 0.7976171, MAE: 0.6941963\n",
      "Epoch: 123, Loss: 0.8077723, MAE: 0.6979753\n",
      "Epoch: 124, Loss: 0.7833922, MAE: 0.6954012\n",
      "Epoch: 125, Loss: 0.7832165, MAE: 0.6900334\n",
      "Epoch: 126, Loss: 0.8594561, MAE: 0.7051763\n",
      "Epoch: 127, Loss: 0.7923970, MAE: 0.6967805\n",
      "Epoch: 128, Loss: 0.7818371, MAE: 0.6949803\n",
      "Epoch: 129, Loss: 0.8138326, MAE: 0.6950225\n",
      "Epoch: 130, Loss: 0.7782278, MAE: 0.6930303\n",
      "Epoch: 131, Loss: 0.7658259, MAE: 0.6942052\n",
      "Epoch: 132, Loss: 0.7658632, MAE: 0.6912037\n",
      "Epoch: 133, Loss: 0.7640149, MAE: 0.6837747\n",
      "Epoch: 134, Loss: 0.7626296, MAE: 0.6878896\n",
      "Epoch: 135, Loss: 0.7658098, MAE: 0.6880109\n",
      "Epoch: 136, Loss: 0.7582209, MAE: 0.6923080\n",
      "Epoch: 137, Loss: 0.7589608, MAE: 0.6915820\n",
      "Epoch: 138, Loss: 0.7595693, MAE: 0.6874635\n",
      "Epoch: 139, Loss: 0.7512810, MAE: 0.6904899\n",
      "Epoch: 140, Loss: 0.7485012, MAE: 0.6883270\n",
      "Epoch: 141, Loss: 0.7453143, MAE: 0.6854166\n",
      "Epoch: 142, Loss: 0.7511765, MAE: 0.6836976\n",
      "Epoch: 143, Loss: 0.7426233, MAE: 0.6839183\n",
      "Epoch: 144, Loss: 0.7345370, MAE: 0.6849498\n",
      "Epoch: 145, Loss: 0.7545133, MAE: 0.6897627\n",
      "Epoch: 146, Loss: 0.9314539, MAE: 0.7098691\n",
      "Epoch: 147, Loss: 0.8369767, MAE: 0.7052526\n",
      "Epoch: 148, Loss: 0.8022947, MAE: 0.6951400\n",
      "Epoch: 149, Loss: 0.7886703, MAE: 0.6896051\n",
      "Epoch: 150, Loss: 0.7864847, MAE: 0.6947993\n",
      "Epoch: 151, Loss: 0.7557491, MAE: 0.6911413\n",
      "Epoch: 152, Loss: 0.7507007, MAE: 0.6929535\n",
      "Epoch: 153, Loss: 0.7341311, MAE: 0.6896710\n",
      "Epoch: 154, Loss: 0.7269764, MAE: 0.6873097\n",
      "Epoch: 155, Loss: 0.7209784, MAE: 0.6886375\n",
      "Epoch: 156, Loss: 0.7254495, MAE: 0.6918256\n",
      "Epoch: 157, Loss: 0.7196139, MAE: 0.6872919\n",
      "Epoch: 158, Loss: 0.7179393, MAE: 0.6848713\n",
      "Epoch: 159, Loss: 0.7126715, MAE: 0.6875312\n",
      "Epoch: 160, Loss: 0.7271296, MAE: 0.6847266\n",
      "Epoch: 161, Loss: 0.7149172, MAE: 0.6797684\n",
      "Epoch: 162, Loss: 0.7063269, MAE: 0.6827546\n",
      "Epoch: 163, Loss: 0.7024776, MAE: 0.6764539\n",
      "Epoch: 164, Loss: 0.7036460, MAE: 0.6793751\n",
      "Epoch: 165, Loss: 0.6967645, MAE: 0.6764929\n",
      "Epoch: 166, Loss: 0.6957083, MAE: 0.6789300\n",
      "Epoch: 167, Loss: 0.7167201, MAE: 0.6755949\n",
      "Epoch: 168, Loss: 0.6993309, MAE: 0.6746311\n",
      "Epoch: 169, Loss: 0.7081624, MAE: 0.6783730\n",
      "Epoch: 170, Loss: 0.8339056, MAE: 0.6910053\n",
      "Epoch: 171, Loss: 0.7176469, MAE: 0.6758844\n",
      "Epoch: 172, Loss: 0.7526026, MAE: 0.6853991\n",
      "Epoch: 173, Loss: 0.7110142, MAE: 0.6823080\n",
      "Epoch: 174, Loss: 0.6938741, MAE: 0.6766349\n",
      "Epoch: 175, Loss: 0.6902206, MAE: 0.6796308\n",
      "Epoch: 176, Loss: 0.6892425, MAE: 0.6814144\n",
      "Epoch: 177, Loss: 0.6956291, MAE: 0.6810097\n",
      "Epoch: 178, Loss: 0.6818627, MAE: 0.6760174\n",
      "Epoch: 179, Loss: 0.6824991, MAE: 0.6905611\n",
      "Epoch: 180, Loss: 0.6778298, MAE: 0.6869365\n",
      "Epoch: 181, Loss: 0.7274240, MAE: 0.6791370\n",
      "Epoch: 182, Loss: 0.6978650, MAE: 0.6731811\n",
      "Epoch: 183, Loss: 0.6941698, MAE: 0.6792005\n",
      "Epoch: 184, Loss: 0.7006683, MAE: 0.6822182\n",
      "Epoch: 185, Loss: 0.9431898, MAE: 0.7303925\n",
      "Epoch: 186, Loss: 0.8481573, MAE: 0.6804032\n",
      "Epoch: 187, Loss: 0.7585498, MAE: 0.6749583\n",
      "Epoch: 188, Loss: 0.7245770, MAE: 0.6767997\n",
      "Epoch: 189, Loss: 0.7032101, MAE: 0.6692026\n",
      "Epoch: 190, Loss: 0.6900505, MAE: 0.6673018\n",
      "Epoch: 191, Loss: 0.6712741, MAE: 0.6701325\n",
      "Epoch: 192, Loss: 0.6682855, MAE: 0.6744792\n",
      "Epoch: 193, Loss: 0.6682300, MAE: 0.6731430\n",
      "Epoch: 194, Loss: 0.6605422, MAE: 0.6674807\n",
      "Epoch: 195, Loss: 0.6572934, MAE: 0.6771392\n",
      "Epoch: 196, Loss: 0.7541785, MAE: 0.6791959\n",
      "Epoch: 197, Loss: 0.6736322, MAE: 0.6712818\n",
      "Epoch: 198, Loss: 0.6605879, MAE: 0.6744170\n",
      "Epoch: 199, Loss: 0.6584049, MAE: 0.6656893\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "mae = eval(validate_loader)\n",
    "print(f'Epoch: 0, MAE: {mae:.7f}')\n",
    "for epoch in range(1, 200):\n",
    "    loss = train(train_loader)\n",
    "    mae = eval(validate_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.7f}, MAE: {mae:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykihqvj1-ZOK",
    "outputId": "daf9030f-2744-4636-d78c-789f3de1df3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gdb_59377</td>\n",
       "      <td>1.450459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gdb_14632</td>\n",
       "      <td>3.597212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gdb_35326</td>\n",
       "      <td>1.688538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gdb_11448</td>\n",
       "      <td>2.629341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gdb_35889</td>\n",
       "      <td>3.674875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Names    labels\n",
       "0  gdb_59377  1.450459\n",
       "1  gdb_14632  3.597212\n",
       "2  gdb_35326  1.688538\n",
       "3  gdb_11448  2.629341\n",
       "4  gdb_35889  3.674875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "model.eval()\n",
    "Ys = []\n",
    "Names = []\n",
    "for data in test_loader:\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    ys = out.to(\"cpu\").tolist()\n",
    "    Ys += ys\n",
    "    Names += data['name']\n",
    " \n",
    "assert(len(Names) == len(Ys))\n",
    "df = pd.DataFrame({\"Names\": Names, \"labels\": Ys})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ib5a1tFn-ZOK"
   },
   "outputs": [],
   "source": [
    "#Upload solution\n",
    "df.columns = ['Idx', 'labels']\n",
    "df.to_csv(\"/home/liucmu/pps3/PYG/GCNN/data2/Y_sample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GNN_example.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
