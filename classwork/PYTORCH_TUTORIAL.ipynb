{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHnQTYUwoh3l"
      },
      "source": [
        "# **What is Pytorch?**\n",
        "\n",
        "Pytorch is a python-based scientific computing package targeted for\n",
        "\n",
        "1.   replacement for NumPy to use the power of GPUs\n",
        "2.   deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **What is a Tensor?**\n",
        "\n",
        "Similar to NumPyâ€™s ndarrays, but can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_FbK8f7pWPJ"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9v4GRlApmWP"
      },
      "source": [
        "A tensor can have different datatypes;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSbAFbE7p23C"
      },
      "source": [
        "x = torch.zeros(1, 3, dtype=torch.long)\n",
        "print(\"\\nx datatype:\",x.dtype)\n",
        "print(\"x: \", x)\n",
        "\n",
        "y = torch.zeros(1, 3, dtype=torch.float)\n",
        "print(\"\\ny datatype:\", y.dtype)\n",
        "print(\"y: \", y)\n",
        "\n",
        "z = torch.zeros(1, 3, dtype=torch.double)\n",
        "print(\"\\nz datatype:\",z.dtype)\n",
        "print(\"z: \", z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htdXJDfmrW7z"
      },
      "source": [
        "A tensor can be constructed \n",
        "1. directly from data;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG2VP9mIrXva"
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_moo-Ur0CF"
      },
      "source": [
        "2. based on an existing tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXK9xWXqr_bk"
      },
      "source": [
        "x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "y = torch.randn_like(x)                       #result will have the same size \n",
        "print(y)                                      \n",
        "\n",
        "z = torch.randn_like(y, dtype=torch.float)    # override dtype!\n",
        "print(z)  \n",
        "\n",
        "#get sizes of tensors;\n",
        "\n",
        "print(\"\\nSize of the tensors:\\n\",x.size(), y.size(), z.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor indexing is similar to numpy"
      ],
      "metadata": {
        "id": "ff_W4iyarZnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic \n",
        "x = torch.randint(0,10,size=(3,4,5)) # 3D tensor\n",
        "\n",
        "print('Original Tensor x:')\n",
        "print(x)\n",
        "print('\\n')\n",
        "\n",
        "# Some valid ways of accessing individual elements in the tensor\n",
        "print('x[0][0][0]\\n', x[0][0][0])\n",
        "print('x[1,2,3]\\n', x[1,2,3])\n",
        "print('x[-1,-1][2]\\n', x[-1,-1][2])\n",
        "print('x[-1,-1][-1]\\n', x[-1,-1][-1])\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "N2c5ozMprdw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors can be sliced"
      ],
      "metadata": {
        "id": "sQZXfkOBsO1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original Tensor x:')\n",
        "print(x)\n",
        "print('\\n')\n",
        "\n",
        "print('x[0] (first dim.) \\n', x[0].shape,'\\n',x[0])\n",
        "print('x[:1] (first dim.) \\n', x[:1].shape,'\\n',x[:1])\n",
        "print('x[:,1] (all dim. row=1) \\n', x[:,1])\n",
        "print('x[:,:,3] (all dim. all rows but only 3rd column) \\n', x[:,:,3].shape,'\\n',x[:,:,3])\n",
        "print('x[:,:,-2:] (all dim., all rows but last 2 columns) \\n',x[:,:,-2:].shape,'\\n', x[:,:,-2:])"
      ],
      "metadata": {
        "id": "xQNSOtIqsRtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vODYPzjYvAyb"
      },
      "source": [
        "---\n",
        "# **Tensor Operations:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Operations can be performed with different syntaxes. For addition;"
      ],
      "metadata": {
        "id": "2b_RDkeU-Qf6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC3lJAJDvSVc"
      },
      "source": [
        "#syntax 1:\n",
        "x = torch.rand(2, 3)\n",
        "y = torch.randn_like(x)\n",
        "print(x + y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBFY3Bdvvhbz"
      },
      "source": [
        "#syntax 2:\n",
        "print(torch.add(x, y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcAIOqwYv7W_"
      },
      "source": [
        "#syntax 4: in-place, post-fixed with an _\n",
        "print(y)\n",
        "\n",
        "y.add_(x)\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjZPa1sZvrSN"
      },
      "source": [
        "#syntax 3: an output tensor as argument\n",
        "result = torch.empty(2, 3)\n",
        "torch.add(x, y, out=result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reduction operations (sum(), mean(), std(), max(), argmax(), prod(), unique() etc.)"
      ],
      "metadata": {
        "id": "-grS8Y8M9QJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.ones(3)\n",
        "x2 = torch.ones(size=(3,4))\n",
        "\n",
        "print('\\noriginal x1:')\n",
        "print(x1)\n",
        "\n",
        "print('\\noriginal x2:')\n",
        "print(x2)\n",
        "\n",
        "print('\\nx1.sum()')\n",
        "print(x1.sum())\n",
        "print(torch.sum(x1))\n",
        "\n",
        "print('\\nx2.sum()')\n",
        "print(x2.sum())\n",
        "print(torch.sum(x2))\n",
        "\n",
        "print('\\nx2.sum(axis=0)')\n",
        "print(x2.sum(axis=0))\n",
        "print(torch.sum(x2, axis=0))\n",
        "\n",
        "print('\\nx2.sum(axis=1)')\n",
        "print(x2.sum(axis=1))\n",
        "print(torch.sum(x2, axis=1))"
      ],
      "metadata": {
        "id": "1YD5yiV59SYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Handling Tensors:**"
      ],
      "metadata": {
        "id": "lzc332nH9pjl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMXNsgRbxbWg"
      },
      "source": [
        "## Resize/reshape a tensor with `torch.view` and `torch.reshape`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.view"
      ],
      "metadata": {
        "id": "_QF0sEQ03KuV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rrCRqC7xx-R"
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.reshape"
      ],
      "metadata": {
        "id": "wd3WhxCz3Nmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randint(0,100,size=(3,4,5))\n",
        "print('Orginal tensor shape: ', x.shape)\n",
        "print('\\n')\n",
        "print('Shape to have 12 rows and 5 columns (x.reshape((12,5))): \\n')\n",
        "print(x.reshape((12,5)), x.reshape((12,5)).shape)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Shape to have 10 rows and using -1 to infer based on the elements in other dimensions (x.reshape(10,-1)): \\n')\n",
        "print(x.reshape(10,-1), x.reshape(10,-1).shape) # Can use -1 to specify one of the dimensions which is automatically inferred based on the elements in other dimensions\n",
        "print(\"----------------\")\n",
        "print('\\n')\n",
        "print('Reshape to have 4 rows and 3 columns (x.reshape(5,4,3)): \\n')\n",
        "print(x.reshape(5,4,3), x.reshape(5,4,3).shape)\n",
        "print('\\n')\n",
        "print(\"----------------\")\n",
        "print('Reshape to single dimension (x.reshape(-1))\\n')\n",
        "print(x.reshape(-1), x.reshape(-1).shape)"
      ],
      "metadata": {
        "id": "38EaRsiCycKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnORYt7VyVNz"
      },
      "source": [
        "## Get the value as a Python number from a one element tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzaKj9r0yXN0"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multidimensional tensors can be changed to singe dimension with Flatten"
      ],
      "metadata": {
        "id": "t7sb67gbuGR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#x = torch.rand(size=(3,4,5)) # 3D tensor\n",
        "x = torch.randint(0,20,size=(3,4,5))  # 3D tensor\n",
        "print(x) \n",
        "print(x.shape)               # 3x4x5\n",
        "print(x.flatten())\n",
        "print(x.flatten().shape)     # 60"
      ],
      "metadata": {
        "id": "vn-tVIG8uFp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dimensions can be added or removed with squeeze and unsqueeze "
      ],
      "metadata": {
        "id": "DBSAnT-suf3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   ### Add dimension with unsequeeze"
      ],
      "metadata": {
        "id": "Km6mtJCL099t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#x = torch.rand(size=(3,4,5))\n",
        "x = torch.randint(0,20,size=(3,4,5))\n",
        "xs = x.unsqueeze(dim=0)   # unsequeeze along axis 0\n",
        "xs2 = x.unsqueeze(1)  # unsequeeze along axis 1\n",
        "\n",
        "print(xs) # A new dimension is added while all the following dimension are incremented by 1 ( positionally)\n",
        "print('\\n')\n",
        "print('Original tensor shape',x.shape)\n",
        "print('Unsequeeze along axis 0 (x.unsqueeze(dim=0))',xs.shape)\n",
        "print('\\n')\n",
        "\n",
        "print(xs.unsqueeze(0)) # Can apply this operation as many times as required\n",
        "print('xs.unsqueeze(0).shape:',xs.unsqueeze(0).shape)\n",
        "print('\\n')\n",
        "print(\"---------\\n\")\n",
        "print('\\n')\n",
        "print('Original tensor\\n')\n",
        "print(x)\n",
        "print('Unsequeeze along axis 1 (x.unsqueeze(1)) : ',xs2.shape)\n",
        "\n",
        "print(xs2) # Unsqueeze can also be applied to other intermediate dimensions\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "7S0fVtyuucwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove dimension with sequeeze"
      ],
      "metadata": {
        "id": "L6MGPQ6Zxk2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"xs.shape : \",xs.shape)\n",
        "print('Original tensor xs\\n')\n",
        "print(xs)\n",
        "print(\"sequeze axis 0 xs.squeeze(0)\")\n",
        "print(xs.squeeze(0))\n",
        "print('xs.squeeze(0).shape:',xs.squeeze(0).shape)\n",
        "print('\\n')\n",
        "print(\"-------------\")\n",
        "print(\"xs2.shape : \",xs2.shape)\n",
        "print('Original tensor xs2\\n')\n",
        "print(xs2)\n",
        "print(\"sequeze axis 1 with xs2.squeeze(1)\")\n",
        "print(xs2.squeeze(1))\n",
        "print('xs2.squeeze(1).shape:',xs2.squeeze(1).shape)\n",
        "print('\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "JfDx9SZBxfc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining Tensors"
      ],
      "metadata": {
        "id": "zCSFLA8F_MY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenate"
      ],
      "metadata": {
        "id": "HKUUkpOq3tFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.randint(0,10,size=(2,3,4))\n",
        "x2 = torch.randint(0,10,size=(2,3,4))\n",
        "\n",
        "print('x1:\\n', x1, \"\\n\")\n",
        "print('x2:\\n', x2, \"\\n\")\n",
        "\n",
        "print('CONCATENATING TENSORS\\n')\n",
        "\n",
        "print('Concatenating two tensors along axis 1 (torch.cat([x1,x2],dim=1))')\n",
        "print(torch.cat([x1,x2],dim=1))\n",
        "print('New Shape: ', torch.cat([x1,x2],dim=1).shape)"
      ],
      "metadata": {
        "id": "uC5MoIYd24r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x1 shape (2,3,4)\n",
        "# x2 shape (2,3,4)\n",
        "\n",
        "x3 = torch.randint(0,10,size=(1,3,4))\n",
        "x4 = torch.randint(0,10,size=(2,3,1))\n",
        "print('\\nConcatenating three tensors (x1,x2,x3) along axis 0\\n')\n",
        "print(\"x1 shape (2,3,4) : \\n\",x1,\"\\n\")\n",
        "print(\"x2 shape (2,3,4) : \\n\",x2,\"\\n\")\n",
        "print('x3 (size=(1,3,4)):\\n', x3, \"\\n\")\n",
        "print('Concatenate with torch.cat([x1,x2,x3],dim=0)')\n",
        "print(torch.cat([x1,x2,x3],dim=0))\n",
        "print('New Shape: ', torch.cat([x1,x2,x3],dim=0).shape)\n",
        "print(\"---------------------------\")\n",
        "print('\\nConcatenating three tensors (x1,x2,x4) along axis 2\\n')\n",
        "print(\"x1 shape (2,3,4) : \\n\",x1,\"\\n\")\n",
        "print(\"x2 shape (2,3,4) : \\n\",x2,\"\\n\")\n",
        "print('x4 (size=(2,3,1)):\\n', x4, \"\\n\")\n",
        "\n",
        "print('Concatenate with torch.cat([x1,x2,x4],dim=2)')\n",
        "print(torch.cat([x1,x2,x4],dim=2))\n",
        "print('New Shape: ', torch.cat([x1,x2,x4],dim=2).shape)"
      ],
      "metadata": {
        "id": "OfllpE4D4Whb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stacking (similar to a combination of unsqueeze and cat)"
      ],
      "metadata": {
        "id": "nyo1lMzY6wBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.randint(0,10,size=(3,4)) \n",
        "x2 = torch.randint(0,10,size=(3,4))\n",
        "print('x1: \\n')\n",
        "print(x1.shape)\n",
        "print(x1)\n",
        "print('\\n')\n",
        "print('x2: \\n')\n",
        "print(x2.shape)\n",
        "print(x2)\n",
        "print('\\n')\n",
        "\n",
        "print('stack x1 and x2 at dim=0 : (3, 4) --> (1, 3, 4) --> (N, 3, 4) \\n')\n",
        "print(torch.stack([x1,x2],dim=0)) #(3, 4) --> (1, 3, 4) --> (N, 3, 4)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=0).shape, '\\n')\n",
        "print('stack x1 and x2 at dim=1: (3, 4) --> (3, 1, 4) --> (3, N, 4) \\n')\n",
        "print(torch.stack([x1,x2],dim=1)) #(3, 4) --> (3, 1, 4) --> (3, N, 4)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=1).shape, '\\n')\n",
        "print('stack x1 and x2 at dim=2: (3, 4) --> (3, 4, 1) --> (3, 4, N) \\n')\n",
        "print(torch.stack([x1,x2],dim=2)) #(3, 4) --> (3, 4, 1) --> (3, 4, N)\n",
        "print(\"New Shape:\", torch.stack([x1,x2],dim=2).shape, '\\n')"
      ],
      "metadata": {
        "id": "NtNmg-aq6x7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Padding"
      ],
      "metadata": {
        "id": "dUnnbb5Z8PkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.tensor([[1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4],\n",
        "                 [1,2,3,4]])\n",
        "\n",
        "pad_left   = 1\n",
        "pad_right  = 2\n",
        "pad_top    = 1\n",
        "pad_bottom = 2\n",
        " \n",
        "x_pad = F.pad(x, (pad_left,pad_right,pad_top,pad_bottom), mode = 'constant', value=100)\n",
        "print(x_pad)\n"
      ],
      "metadata": {
        "id": "ix5e2VEI8McX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "584dHoKDzOc9"
      },
      "source": [
        "For 100+ Tensor operations you can visit;\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Vector/Matrix operations**"
      ],
      "metadata": {
        "id": "9pnBBTc087ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector-Vector"
      ],
      "metadata": {
        "id": "NZaNLuHKAjnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.randn(3)\n",
        "tensor2 = torch.randn(3)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ],
      "metadata": {
        "id": "ma9WeU4lA0Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector-Matrix"
      ],
      "metadata": {
        "id": "yblHh9F7AyPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.randn(3, 4)\n",
        "tensor2 = torch.randn(4)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ],
      "metadata": {
        "id": "XPo38Ku3ByfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matrix-Matrix"
      ],
      "metadata": {
        "id": "DaGupG3FB-Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.randn(3, 4)\n",
        "tensor2 = torch.randn(4, 5)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ],
      "metadata": {
        "id": "AUlBUKs5CHw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.randn(2, 3, 4)\n",
        "tensor2 = torch.randn(2, 4, 5)\n",
        "\n",
        "print('tensor1')\n",
        "print(tensor1.size())\n",
        "print(tensor1,'\\n')\n",
        "\n",
        "print('tensor2')\n",
        "print(tensor2.size())\n",
        "print(tensor2,'\\n')\n",
        "\n",
        "print('===========\\n')\n",
        "print('tensor1 @ tensor2')\n",
        "print((tensor1 @ tensor2).size())\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print('torch.matmul(tensor1, tensor2)')\n",
        "print(torch.matmul(tensor1, tensor2).size())\n",
        "print(torch.matmul(tensor1, tensor2),'\\n')"
      ],
      "metadata": {
        "id": "bS248-PNCer2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol-D5VGEzkG2"
      },
      "source": [
        "---\n",
        "# **Converting a Torch tensor to a NumPy array, and vice versa**\n",
        "\n",
        "Torch tensors and numpy arrays can be converted to each other. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgdtmEgE0GH-"
      },
      "source": [
        "#tensor to numpy\n",
        "x = torch.ones(5)\n",
        "print(x)\n",
        "y = x.numpy()\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8hKRHxs1h_e"
      },
      "source": [
        "#numpy to tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skX8vcFY1CvO"
      },
      "source": [
        "If underlying memory locations is on CPU, changing one will change the other; "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs9t5ed_1OHT"
      },
      "source": [
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az4LUKuV1fvU"
      },
      "source": [
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0T8AGbH12F-"
      },
      "source": [
        "---\n",
        "# **CUDA Tensors**\n",
        "\n",
        "Tensors can be moved onto any device using the `.to` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzWeMu4d2DKQ"
      },
      "source": [
        "# run this cell only if CUDA is available\n",
        "# Use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_SvvIGUYeN3"
      },
      "source": [
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCWblVgRAo6F"
      },
      "source": [
        "---\n",
        "# **`Autograd` Package**\n",
        "\n",
        " \n",
        "\n",
        "* Provides automatic differentiation for all operations on Tensors\n",
        "* A define-by-run framework (backprop is defined by how the code is run, and that every single iteration can be different)\n",
        "* If the attribute `.requires_grad`  of a tensor is set to as `True`, all opeations on the tensor will be tracked\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CR2vt1lC6ee"
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrmO-TZyDspo"
      },
      "source": [
        "#y was created as a result of an operation, so it has a grad_fn.\n",
        "print(y.grad_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8uCi4ONDwjl"
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIhuuDoxDoka"
      },
      "source": [
        "#change an existing tensorâ€™s requires_grad flag in-place\n",
        "\n",
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z05jRG-2DR12"
      },
      "source": [
        "* When the computation is finished, `.backward()` can be calle to compute all the gradients automatically (gadient will be accumulated into `.grad` attribute)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFM6_oJfEUej"
      },
      "source": [
        "out.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGkAOH1YESUV"
      },
      "source": [
        "* You can also stop autograd from tracking history by wrapping the code block in with torch.no_grad():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLLP63igFIhG"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1M_lELkFo6l"
      },
      "source": [
        "* For more infomation: https://pytorch.org/docs/stable/autograd.html#function\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHlkLJNCF0LJ"
      },
      "source": [
        "---\n",
        "# **Neural Networks (NN)**\n",
        "\n",
        "* NN can be construted with `torch.nn` package.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSYPwdhtGc1o"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfJ_jUwRQ_qo"
      },
      "source": [
        "* nn depends on autograd to define models and differentiate them. \n",
        "* A typical training procedure for a neural network is as follows:\n",
        "\n",
        "    **i.** Define the neural network that has some learnable parameters (or weights). \n",
        "    \n",
        "    > The learnable parameters of a model are returned by net.parameters()\n",
        "\n",
        "  **ii.** Iterate over a dataset of inputs\n",
        "\n",
        "    **iii.** Process input through the network\n",
        "\n",
        "    **iv.** Compute the loss (how far is the output from being correct).\n",
        "\n",
        "    **v.** Propagate gradients back into the networkâ€™s parameters with loss.backward()\n",
        "\n",
        "    **vi.** Update the weights of the network. \n",
        "\n",
        "    > This can be performed by any of the various different update rules that are implemented in `torch.optim` package \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttXXwJEqQNu3"
      },
      "source": [
        "#CREATE INPUT, AND OUTPUT \n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "print(x.size(), y.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ro9m4BQlTW"
      },
      "source": [
        "#DEFINE NN:\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    #ReLU: rectified linear unit\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5eLJut3RT4_"
      },
      "source": [
        "#LEARNABLE PARAMETERS IN THE MODEL:\n",
        "params = list(model.parameters())\n",
        "print(\"Lenght of learnable parameters: \",len(params))\n",
        "print(\"Size of the first parameter: \", params[0].size()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4RmEFGaTEz-"
      },
      "source": [
        "# WE WILL NEED A LOSS FUNCTION FOR STEP iv.\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "print(\"Loss function:\", loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLNQlNlbKNzl"
      },
      "source": [
        "# TO UPDATE WEIGHTS, LETS USE ADAM \n",
        "# THAT IS ALREAY IMPLEMENTED IN torch.optim\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"Optimizer: \", optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIWsyb0zVzX3"
      },
      "source": [
        " #TRAINING LOOP:\n",
        "for t in range(500):\n",
        "\n",
        "    # Forward pass: \n",
        "    # Feed input to the model \n",
        "    # and compute predicted.\n",
        " \n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    #with torch.no_grad():\n",
        "    #    for param in model.parameters():\n",
        "    #        param -= learning_rate * param.grad\n",
        "\n",
        "\n",
        "    # and update the weights.\n",
        "    \n",
        "    optimizer.step()            \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwTP0YKMQ3pS"
      },
      "source": [
        "---\n",
        "# **Training an image classifier**\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
        "2. Define a Convolutional Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x_sKrxzRMTf"
      },
      "source": [
        "**1. Loading and normalizing CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJbcmsfRx-Ks"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "########################################################################\n",
        "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1].\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-SVwefYRhBb"
      },
      "source": [
        "Let us show some of the training images, for fun."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68BrNCxURajK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "#images, labels = dataiter.next()\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVwlDD03RvqN"
      },
      "source": [
        "**2. Define a Convolutional Neural Network**\n",
        "\n",
        "CNNs systematically apply learned filters to input images in order to \n",
        "create feature maps that summarize the presence of those features in the input.\n",
        "\n",
        "We will use Conv2d for convolution layers. It applies a 2D convolution over an input signal composed of several input planes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv2D input : $(N,C_{in},H_{in},W_{in})$ or  $(C_{in},H_{in},W_{in})$\n",
        "\n",
        "Conv2D output:\n",
        "\n",
        "$H_{out} = \\frac{H_{in} + 2 * padding[0] - dilation[0]*(kernel_{-}size[0]-1)-1}{stride[0]} +1$\n",
        "\n",
        "$W_{out} = \\frac{W_{in} + 2 * padding[1] - dilation[1]*(kernel_{-}size[1]-1)-1}{stride[1]} +1$\n"
      ],
      "metadata": {
        "id": "yIcwpZBJVfyn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiOITK9ovvn0"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#if we use equation given above\n",
        "#input size:   32x32x3\n",
        "#After conv1   28x28x6\n",
        "#After pooling 14x14x6\n",
        "#After conv2   10x10x16\n",
        "#After pooling 5x5x16\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        #takes 3-channel images, 6 output channels, 5x5 square convolution kernel\n",
        "        #initialize 6 5x5-kernels, each having a total of 3 channels \n",
        "        #color images of 32x32 pixels in size\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\n",
        "        #A limitation of the feature map output of convolutional \n",
        "        #layers is that they record the precise position of features \n",
        "        #in the input. This means that small movements in the \n",
        "        #position of the feature in the input image will result in a \n",
        "        #different feature map.This can happen with re-cropping, rotation, \n",
        "        #shifting, and other minor changes to the input image.\n",
        "        #A common approach to addressing this problem from signal \n",
        "        #processing is called down sampling. This is where a lower \n",
        "        #resolution version of an input signal is created that still \n",
        "        #contains the large or important structural elements.\n",
        "        #A more robust and common approach is to use a POOLING LAYER.\n",
        "        #A pooling layer is a new layer added \n",
        "        #after the convolutional layer.\n",
        "        #The pooling layer operates upon each feature map separately \n",
        "        #to create a new set of the same number of pooled feature maps.\n",
        "        #The size of the pooling operation or filter is smaller than the \n",
        "        #size of the feature map\n",
        "        self.pool = nn.MaxPool2d(2, 2)  \n",
        "        \n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_A9GyQHaDOU"
      },
      "source": [
        "**3. Define a Loss function and optimizer**\n",
        "\n",
        "Letâ€™s use a Classification Cross-Entropy loss and  stochastic gradient descent (SGD) with momentum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-bJcL9mMEN6"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI6WLMBeaX1q"
      },
      "source": [
        "**4. Train the network**\n",
        "\n",
        "We will loop over our data iterator, and feed the inputs to the network and optimize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpcFrIE8OBKF"
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak_lXZ-CawcU"
      },
      "source": [
        "**5. Test the network on the test data**\n",
        "\n",
        "We need to check if the network has learnt anything at all.\n",
        "We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "First,  let us display an image from the test set to get familiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOFPvWQ-M7Ng"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12jmH6zbXKg"
      },
      "source": [
        "Now let us see what the neural network thinks these examples above are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "achD24npNJs3"
      },
      "source": [
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJEccRoEb5tX"
      },
      "source": [
        "The results seem pretty good. Let us look at how the network performs on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5c8qpdWbv7i"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}